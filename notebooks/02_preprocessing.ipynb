{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f28c486",
   "metadata": {},
   "source": [
    "# Preprocesamiento de Datos\n",
    "## Proyecto de Clasificación Multiclase\n",
    "\n",
    "Este notebook contiene el preprocesamiento necesario para preparar los datos:\n",
    "- División de datos (train/test)\n",
    "- Escalado de características\n",
    "- Selección de características\n",
    "- Manejo de desbalance de clases (si es necesario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab9649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif, mutual_info_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1494f799",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos y Resumen EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27bf269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "df = pd.read_csv('../datasets/train.csv')\n",
    "\n",
    "# Cargar resumen del EDA si existe\n",
    "try:\n",
    "    with open('../results/eda_summary.json', 'r') as f:\n",
    "        eda_summary = json.load(f)\n",
    "    print(\"Resumen del EDA:\")\n",
    "    print(json.dumps(eda_summary, indent=2))\n",
    "except:\n",
    "    print(\"No se encontró el resumen del EDA. Ejecuta primero 01_exploratory_data_analysis.ipynb\")\n",
    "\n",
    "print(f\"\\nDimensiones del dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb7b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar características y objetivo\n",
    "feature_cols = [col for col in df.columns if col not in ['id', 'target']]\n",
    "X = df[feature_cols].copy()\n",
    "y = df['target'].copy()\n",
    "\n",
    "print(f\"Características: {X.shape[1]}\")\n",
    "print(f\"Muestras: {X.shape[0]}\")\n",
    "print(f\"\\nClases únicas: {y.nunique()}\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc01ef1",
   "metadata": {},
   "source": [
    "## 2. Codificación de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar la variable objetivo si es categórica\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"Mapeo de clases:\")\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    print(f\"{class_name} -> {i}\")\n",
    "\n",
    "# Guardar el encoder\n",
    "with open('../models/label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "    \n",
    "print(\"\\n✓ Label Encoder guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa91741",
   "metadata": {},
   "source": [
    "## 3. División de Datos (Train/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec345637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División estratificada para mantener la proporción de clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(\"Conjunto de entrenamiento:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"\\nConjunto de prueba:\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")\n",
    "\n",
    "# Verificar distribución de clases\n",
    "print(\"\\nDistribución en train:\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True).sort_index())\n",
    "print(\"\\nDistribución en test:\")\n",
    "print(pd.Series(y_test).value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16384fe8",
   "metadata": {},
   "source": [
    "## 4. Eliminación de Características con Baja Varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44423f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar características con varianza casi nula\n",
    "variance_selector = VarianceThreshold(threshold=0.01)\n",
    "X_train_var = variance_selector.fit_transform(X_train)\n",
    "X_test_var = variance_selector.transform(X_test)\n",
    "\n",
    "# Obtener nombres de características seleccionadas\n",
    "selected_features_mask = variance_selector.get_support()\n",
    "selected_features = X_train.columns[selected_features_mask].tolist()\n",
    "\n",
    "print(f\"Características originales: {X_train.shape[1]}\")\n",
    "print(f\"Características después de eliminar baja varianza: {X_train_var.shape[1]}\")\n",
    "print(f\"Características eliminadas: {X_train.shape[1] - X_train_var.shape[1]}\")\n",
    "\n",
    "# Convertir a DataFrame\n",
    "X_train_var = pd.DataFrame(X_train_var, columns=selected_features, index=X_train.index)\n",
    "X_test_var = pd.DataFrame(X_test_var, columns=selected_features, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c45856",
   "metadata": {},
   "source": [
    "## 5. Escalado de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637fb080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler (estandarización: media=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_var)\n",
    "X_test_scaled = scaler.transform(X_test_var)\n",
    "\n",
    "# Convertir a DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=selected_features, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=selected_features, index=X_test.index)\n",
    "\n",
    "print(\"✓ Datos escalados usando StandardScaler\")\n",
    "print(f\"\\nEstadísticas después del escalado (primeras 5 características):\")\n",
    "print(X_train_scaled.iloc[:, :5].describe())\n",
    "\n",
    "# Guardar el scaler\n",
    "with open('../models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"\\n✓ Scaler guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113a1e7e",
   "metadata": {},
   "source": [
    "## 6. Selección de Características (Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las K mejores características usando ANOVA F-value\n",
    "k_best = min(50, X_train_scaled.shape[1])  # Seleccionar hasta 50 características o todas si hay menos\n",
    "\n",
    "selector_f = SelectKBest(score_func=f_classif, k=k_best)\n",
    "X_train_selected_f = selector_f.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected_f = selector_f.transform(X_test_scaled)\n",
    "\n",
    "# Obtener características seleccionadas\n",
    "selected_mask_f = selector_f.get_support()\n",
    "selected_features_f = [feat for feat, selected in zip(selected_features, selected_mask_f) if selected]\n",
    "\n",
    "print(f\"Características seleccionadas (ANOVA F-value): {len(selected_features_f)}\")\n",
    "print(f\"\\nTop 10 características por importancia:\")\n",
    "feature_scores = pd.DataFrame({\n",
    "    'feature': selected_features,\n",
    "    'score': selector_f.scores_\n",
    "}).sort_values('score', ascending=False)\n",
    "print(feature_scores.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar las mejores características\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_features = feature_scores.head(20)\n",
    "plt.barh(top_features['feature'], top_features['score'], color='steelblue', edgecolor='black')\n",
    "plt.xlabel('F-Score', fontsize=12)\n",
    "plt.ylabel('Características', fontsize=12)\n",
    "plt.title('Top 20 Características por Importancia (ANOVA F-value)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11e2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección usando Información Mutua\n",
    "selector_mi = SelectKBest(score_func=mutual_info_classif, k=k_best)\n",
    "X_train_selected_mi = selector_mi.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected_mi = selector_mi.transform(X_test_scaled)\n",
    "\n",
    "selected_mask_mi = selector_mi.get_support()\n",
    "selected_features_mi = [feat for feat, selected in zip(selected_features, selected_mask_mi) if selected]\n",
    "\n",
    "print(f\"Características seleccionadas (Mutual Information): {len(selected_features_mi)}\")\n",
    "print(f\"\\nCaracterísticas comunes entre ambos métodos: {len(set(selected_features_f) & set(selected_features_mi))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0e36fc",
   "metadata": {},
   "source": [
    "## 7. Manejo de Desbalance de Clases (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7038d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si hay desbalance significativo\n",
    "class_distribution = pd.Series(y_train).value_counts()\n",
    "balance_ratio = class_distribution.max() / class_distribution.min()\n",
    "\n",
    "print(f\"Ratio de desbalance: {balance_ratio:.2f}\")\n",
    "\n",
    "if balance_ratio > 2:\n",
    "    print(\"\\n⚠️ Detectado desbalance de clases. Aplicando SMOTE...\")\n",
    "    \n",
    "    # Aplicar SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_selected_f, y_train)\n",
    "    \n",
    "    print(f\"\\nMuestras antes de SMOTE: {X_train_selected_f.shape[0]}\")\n",
    "    print(f\"Muestras después de SMOTE: {X_train_resampled.shape[0]}\")\n",
    "    print(f\"\\nDistribución después de SMOTE:\")\n",
    "    print(pd.Series(y_train_resampled).value_counts().sort_index())\n",
    "else:\n",
    "    print(\"✓ Las clases están relativamente balanceadas. No se aplicará SMOTE.\")\n",
    "    X_train_resampled = X_train_selected_f\n",
    "    y_train_resampled = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c16c2",
   "metadata": {},
   "source": [
    "## 8. Guardar Datos Preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cac7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorio si no existe\n",
    "Path('../data/processed').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Guardar conjuntos de datos preprocesados\n",
    "np.save('../data/processed/X_train_scaled.npy', X_train_scaled.values)\n",
    "np.save('../data/processed/X_test_scaled.npy', X_test_scaled.values)\n",
    "np.save('../data/processed/X_train_selected.npy', X_train_selected_f)\n",
    "np.save('../data/processed/X_test_selected.npy', X_test_selected_f)\n",
    "np.save('../data/processed/X_train_resampled.npy', X_train_resampled)\n",
    "np.save('../data/processed/y_train.npy', y_train)\n",
    "np.save('../data/processed/y_test.npy', y_test)\n",
    "np.save('../data/processed/y_train_resampled.npy', y_train_resampled)\n",
    "\n",
    "# Guardar nombres de características\n",
    "with open('../data/processed/selected_features.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'all_features': selected_features,\n",
    "        'selected_features_f': selected_features_f,\n",
    "        'selected_features_mi': selected_features_mi\n",
    "    }, f, indent=2)\n",
    "\n",
    "# Guardar selectores\n",
    "with open('../models/variance_selector.pkl', 'wb') as f:\n",
    "    pickle.dump(variance_selector, f)\n",
    "with open('../models/feature_selector_f.pkl', 'wb') as f:\n",
    "    pickle.dump(selector_f, f)\n",
    "with open('../models/feature_selector_mi.pkl', 'wb') as f:\n",
    "    pickle.dump(selector_mi, f)\n",
    "\n",
    "print(\"✓ Datos preprocesados guardados exitosamente en 'data/processed/'\")\n",
    "print(\"✓ Modelos de preprocesamiento guardados en 'models/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a8105",
   "metadata": {},
   "source": [
    "## 9. Resumen del Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab663f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_summary = {\n",
    "    'original_features': len(feature_cols),\n",
    "    'features_after_variance_threshold': len(selected_features),\n",
    "    'features_selected_f_classif': len(selected_features_f),\n",
    "    'features_selected_mutual_info': len(selected_features_mi),\n",
    "    'train_samples_original': X_train.shape[0],\n",
    "    'train_samples_resampled': X_train_resampled.shape[0],\n",
    "    'test_samples': X_test.shape[0],\n",
    "    'balance_ratio': float(balance_ratio),\n",
    "    'smote_applied': balance_ratio > 2\n",
    "}\n",
    "\n",
    "with open('../results/preprocessing_summary.json', 'w') as f:\n",
    "    json.dump(preprocessing_summary, f, indent=2)\n",
    "\n",
    "print(\"=== RESUMEN DEL PREPROCESAMIENTO ===\")\n",
    "print(json.dumps(preprocessing_summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a40fce",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "✓ Datos divididos en conjuntos de entrenamiento y prueba (80/20)\n",
    "\n",
    "✓ Características escaladas usando StandardScaler\n",
    "\n",
    "✓ Características con baja varianza eliminadas\n",
    "\n",
    "✓ Selección de características más relevantes\n",
    "\n",
    "✓ Manejo de desbalance de clases (si aplica)\n",
    "\n",
    "✓ Datos listos para el modelado\n",
    "\n",
    "### Próximo paso:\n",
    "Construcción y entrenamiento de modelos de clasificación"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
