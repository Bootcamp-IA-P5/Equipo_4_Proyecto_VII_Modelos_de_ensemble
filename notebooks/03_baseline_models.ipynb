{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a627625",
   "metadata": {},
   "source": [
    "# Modelos Base de Clasificación\n",
    "## Proyecto de Clasificación Multiclase\n",
    "\n",
    "Este notebook implementa y evalúa varios modelos base de clasificación:\n",
    "- Logistic Regression\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Support Vector Machine (SVM)\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "\n",
    "Se evaluarán y compararán para establecer una línea base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    roc_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2691dc91",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos Preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b86133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos preprocesados\n",
    "X_train = np.load('../data/processed/X_train_selected.npy')\n",
    "X_test = np.load('../data/processed/X_test_selected.npy')\n",
    "y_train = np.load('../data/processed/y_train_resampled.npy')\n",
    "y_test = np.load('../data/processed/y_test.npy')\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "# Cargar label encoder\n",
    "with open('../models/label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "print(f\"\\nNúmero de clases: {len(label_encoder.classes_)}\")\n",
    "print(f\"Clases: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe09b00e",
   "metadata": {},
   "source": [
    "## 2. Definición de Función de Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5342dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de clasificación\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Evaluando: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Métricas\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Métricas multiclase (promedio weighted)\n",
    "    precision = precision_score(y_test, y_pred_test, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred_test, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_test, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Cross-validation (solo en train para no tocar test)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    print(f\"\\n📊 Resultados:\")\n",
    "    print(f\"  Tiempo de entrenamiento: {training_time:.2f}s\")\n",
    "    print(f\"  Accuracy (Train): {train_accuracy:.4f}\")\n",
    "    print(f\"  Accuracy (Test): {test_accuracy:.4f}\")\n",
    "    print(f\"  Precision (Test): {precision:.4f}\")\n",
    "    print(f\"  Recall (Test): {recall:.4f}\")\n",
    "    print(f\"  F1-Score (Test): {f1:.4f}\")\n",
    "    print(f\"  CV Accuracy (mean ± std): {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "    \n",
    "    # Reporte de clasificación\n",
    "    print(f\"\\n📋 Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred_test, \n",
    "                                target_names=label_encoder.classes_,\n",
    "                                zero_division=0))\n",
    "    \n",
    "    # Matriz de confusión\n",
    "    cm = confusion_matrix(y_test, y_pred_test)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'train_accuracy': float(train_accuracy),\n",
    "        'test_accuracy': float(test_accuracy),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'f1_score': float(f1),\n",
    "        'cv_mean': float(cv_scores.mean()),\n",
    "        'cv_std': float(cv_scores.std()),\n",
    "        'training_time': float(training_time)\n",
    "    }\n",
    "    \n",
    "    return model, results, cm, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, model_name, classes):\n",
    "    \"\"\"\n",
    "    Visualiza la matriz de confusión\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=classes, yticklabels=classes,\n",
    "                cbar_kws={'label': 'Número de predicciones'})\n",
    "    plt.title(f'Matriz de Confusión - {model_name}', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Clase Real', fontsize=12)\n",
    "    plt.xlabel('Clase Predicha', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../results/confusion_matrix_{model_name.replace(\" \", \"_\").lower()}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f8006",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento de Modelos Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f8a03",
   "metadata": {},
   "source": [
    "### 3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a405ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "lr_model, lr_results, lr_cm, lr_pred = evaluate_model(\n",
    "    lr_model, X_train, X_test, y_train, y_test, \"Logistic Regression\"\n",
    ")\n",
    "plot_confusion_matrix(lr_cm, \"Logistic Regression\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4126d657",
   "metadata": {},
   "source": [
    "### 3.2 K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "knn_model, knn_results, knn_cm, knn_pred = evaluate_model(\n",
    "    knn_model, X_train, X_test, y_train, y_test, \"K-Nearest Neighbors\"\n",
    ")\n",
    "plot_confusion_matrix(knn_cm, \"K-Nearest Neighbors\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae53cd1",
   "metadata": {},
   "source": [
    "### 3.3 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6348b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='rbf', random_state=42)\n",
    "svm_model, svm_results, svm_cm, svm_pred = evaluate_model(\n",
    "    svm_model, X_train, X_test, y_train, y_test, \"Support Vector Machine\"\n",
    ")\n",
    "plot_confusion_matrix(svm_cm, \"Support Vector Machine\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef72621",
   "metadata": {},
   "source": [
    "### 3.4 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c3913",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "dt_model, dt_results, dt_cm, dt_pred = evaluate_model(\n",
    "    dt_model, X_train, X_test, y_train, y_test, \"Decision Tree\"\n",
    ")\n",
    "plot_confusion_matrix(dt_cm, \"Decision Tree\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc771eda",
   "metadata": {},
   "source": [
    "### 3.5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, max_depth=15)\n",
    "rf_model, rf_results, rf_cm, rf_pred = evaluate_model(\n",
    "    rf_model, X_train, X_test, y_train, y_test, \"Random Forest\"\n",
    ")\n",
    "plot_confusion_matrix(rf_cm, \"Random Forest\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8568c59",
   "metadata": {},
   "source": [
    "### 3.6 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab02101",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model, nb_results, nb_cm, nb_pred = evaluate_model(\n",
    "    nb_model, X_train, X_test, y_train, y_test, \"Naive Bayes\"\n",
    ")\n",
    "plot_confusion_matrix(nb_cm, \"Naive Bayes\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380be681",
   "metadata": {},
   "source": [
    "## 4. Comparación de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b49b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar todos los resultados\n",
    "all_results = [\n",
    "    lr_results,\n",
    "    knn_results,\n",
    "    svm_results,\n",
    "    dt_results,\n",
    "    rf_results,\n",
    "    nb_results\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('test_accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPARACIÓN DE MODELOS BASE\")\n",
    "print(\"=\"*100)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Guardar resultados\n",
    "results_df.to_csv('../results/base_models_comparison.csv', index=False)\n",
    "print(\"\\n✓ Resultados guardados en 'results/base_models_comparison.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec588601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización comparativa\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Accuracy\n",
    "ax1 = axes[0, 0]\n",
    "results_df_sorted = results_df.sort_values('test_accuracy')\n",
    "ax1.barh(results_df_sorted['model_name'], results_df_sorted['test_accuracy'], color='steelblue', edgecolor='black')\n",
    "ax1.set_xlabel('Accuracy', fontsize=12)\n",
    "ax1.set_title('Test Accuracy por Modelo', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlim([0, 1])\n",
    "for i, v in enumerate(results_df_sorted['test_accuracy']):\n",
    "    ax1.text(v + 0.01, i, f'{v:.4f}', va='center')\n",
    "\n",
    "# F1-Score\n",
    "ax2 = axes[0, 1]\n",
    "results_df_sorted_f1 = results_df.sort_values('f1_score')\n",
    "ax2.barh(results_df_sorted_f1['model_name'], results_df_sorted_f1['f1_score'], color='coral', edgecolor='black')\n",
    "ax2.set_xlabel('F1-Score', fontsize=12)\n",
    "ax2.set_title('F1-Score por Modelo', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlim([0, 1])\n",
    "for i, v in enumerate(results_df_sorted_f1['f1_score']):\n",
    "    ax2.text(v + 0.01, i, f'{v:.4f}', va='center')\n",
    "\n",
    "# Tiempo de entrenamiento\n",
    "ax3 = axes[1, 0]\n",
    "results_df_sorted_time = results_df.sort_values('training_time')\n",
    "ax3.barh(results_df_sorted_time['model_name'], results_df_sorted_time['training_time'], color='lightgreen', edgecolor='black')\n",
    "ax3.set_xlabel('Tiempo (segundos)', fontsize=12)\n",
    "ax3.set_title('Tiempo de Entrenamiento', fontsize=14, fontweight='bold')\n",
    "for i, v in enumerate(results_df_sorted_time['training_time']):\n",
    "    ax3.text(v + 0.1, i, f'{v:.2f}s', va='center')\n",
    "\n",
    "# Métricas combinadas\n",
    "ax4 = axes[1, 1]\n",
    "metrics = ['test_accuracy', 'precision', 'recall', 'f1_score']\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.2\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax4.bar(x + i*width, results_df[metric], width, label=metric.replace('_', ' ').title())\n",
    "\n",
    "ax4.set_xlabel('Modelos', fontsize=12)\n",
    "ax4.set_ylabel('Score', fontsize=12)\n",
    "ax4.set_title('Comparación de Métricas', fontsize=14, fontweight='bold')\n",
    "ax4.set_xticks(x + width * 1.5)\n",
    "ax4.set_xticklabels(results_df['model_name'], rotation=45, ha='right')\n",
    "ax4.legend()\n",
    "ax4.set_ylim([0, 1])\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/base_models_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8605e396",
   "metadata": {},
   "source": [
    "## 5. Análisis del Mejor Modelo Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar el mejor modelo\n",
    "best_model_name = results_df.iloc[0]['model_name']\n",
    "best_model_accuracy = results_df.iloc[0]['test_accuracy']\n",
    "\n",
    "print(f\"\\n🏆 MEJOR MODELO BASE: {best_model_name}\")\n",
    "print(f\"   Accuracy: {best_model_accuracy:.4f}\")\n",
    "print(f\"\\nTop 3 modelos:\")\n",
    "print(results_df[['model_name', 'test_accuracy', 'f1_score']].head(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb11ec3",
   "metadata": {},
   "source": [
    "## 6. Guardar Modelos Entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los modelos entrenados\n",
    "models = {\n",
    "    'logistic_regression': lr_model,\n",
    "    'knn': knn_model,\n",
    "    'svm': svm_model,\n",
    "    'decision_tree': dt_model,\n",
    "    'random_forest': rf_model,\n",
    "    'naive_bayes': nb_model\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    with open(f'../models/{name}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "print(\"✓ Modelos guardados en 'models/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b406f78",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Se han entrenado y evaluado 6 modelos base de clasificación:\n",
    "- ✓ Logistic Regression\n",
    "- ✓ K-Nearest Neighbors\n",
    "- ✓ Support Vector Machine\n",
    "- ✓ Decision Tree\n",
    "- ✓ Random Forest\n",
    "- ✓ Naive Bayes\n",
    "\n",
    "### Observaciones:\n",
    "1. Los modelos ensemble (Random Forest) generalmente superan a los modelos simples\n",
    "2. La comparación de métricas permite identificar el mejor modelo base\n",
    "3. El análisis de matrices de confusión revela errores específicos por clase\n",
    "\n",
    "### Próximo paso:\n",
    "Implementar modelos de ensemble más avanzados (Bagging, Boosting, Stacking)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
