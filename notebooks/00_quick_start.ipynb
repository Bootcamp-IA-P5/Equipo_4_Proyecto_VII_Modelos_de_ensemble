{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5088b3a",
   "metadata": {},
   "source": [
    "# ðŸš€ Quick Start - Inicio RÃ¡pido\n",
    "\n",
    "Este notebook te permite empezar rÃ¡pidamente con el proyecto.\n",
    "Es una versiÃ³n simplificada para probar el flujo completo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e68b9",
   "metadata": {},
   "source": [
    "## 1. Importar LibrerÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "print(\"âœ“ LibrerÃ­as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d71ec5",
   "metadata": {},
   "source": [
    "## 2. Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cee45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "df = pd.read_csv('../datasets/train.csv')\n",
    "\n",
    "print(f\"Dataset cargado: {df.shape}\")\n",
    "print(f\"\\nPrimeras filas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InformaciÃ³n del dataset\n",
    "print(\"InformaciÃ³n del dataset:\")\n",
    "print(f\"- Registros: {len(df):,}\")\n",
    "print(f\"- CaracterÃ­sticas: {df.shape[1] - 2}\")  # -2 por 'id' y 'target'\n",
    "print(f\"\\nDistribuciÃ³n de clases:\")\n",
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88598cbb",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento RÃ¡pido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e299f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features y target\n",
    "X = df.drop(['id', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(f\"Features: {X.shape}\")\n",
    "print(f\"Target: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbdfc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"Clases codificadas:\")\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {class_name} -> {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc324e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DivisiÃ³n train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"âœ“ Datos escalados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d374e44d",
   "metadata": {},
   "source": [
    "## 4. Entrenar Modelo Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4180b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar modelo\n",
    "print(\"Entrenando Random Forest...\")\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=10, \n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"âœ“ Modelo entrenado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127b8fa",
   "metadata": {},
   "source": [
    "## 5. Evaluar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dbea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe98ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de ConfusiÃ³n\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_encoder.classes_, \n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('Matriz de ConfusiÃ³n', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Clase Real')\n",
    "plt.xlabel('Clase Predicha')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8933013",
   "metadata": {},
   "source": [
    "## 6. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de caracterÃ­sticas\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue')\n",
    "plt.xlabel('Importancia')\n",
    "plt.title('Top 20 CaracterÃ­sticas MÃ¡s Importantes', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2079f24",
   "metadata": {},
   "source": [
    "## 7. Ejemplo de PredicciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c403f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomar 5 muestras del test set\n",
    "sample_indices = np.random.choice(len(X_test), 5, replace=False)\n",
    "X_sample = X_test.iloc[sample_indices]\n",
    "X_sample_scaled = scaler.transform(X_sample)\n",
    "y_sample = y_test[sample_indices]\n",
    "\n",
    "# Predecir\n",
    "predictions = model.predict(X_sample_scaled)\n",
    "\n",
    "# Decodificar\n",
    "predictions_decoded = label_encoder.inverse_transform(predictions)\n",
    "actual_decoded = label_encoder.inverse_transform(y_sample)\n",
    "\n",
    "print(\"\\nEjemplo de Predicciones:\")\n",
    "print(\"=\"*50)\n",
    "for i in range(5):\n",
    "    status = \"âœ“\" if predictions[i] == y_sample[i] else \"âœ—\"\n",
    "    print(f\"{status} Muestra {i+1}:\")\n",
    "    print(f\"   Predicho: {predictions_decoded[i]}\")\n",
    "    print(f\"   Real:     {actual_decoded[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b182ab",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ ConclusiÃ³n\n",
    "\n",
    "Â¡Has completado el flujo bÃ¡sico!\n",
    "\n",
    "### PrÃ³ximos pasos:\n",
    "1. Ejecutar los notebooks completos para anÃ¡lisis mÃ¡s profundo\n",
    "2. Probar diferentes modelos (XGBoost, LightGBM, etc.)\n",
    "3. Optimizar hiperparÃ¡metros\n",
    "4. Aplicar tÃ©cnicas de ensemble\n",
    "\n",
    "### Notebooks disponibles:\n",
    "- `01_exploratory_data_analysis.ipynb` - EDA completo\n",
    "- `02_preprocessing.ipynb` - Preprocesamiento avanzado\n",
    "- `03_baseline_models.ipynb` - Modelos base\n",
    "- `04_ensemble_models.ipynb` - Modelos ensemble\n",
    "\n",
    "**Â¡Feliz modelado!** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
