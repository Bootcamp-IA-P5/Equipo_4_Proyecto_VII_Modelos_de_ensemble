{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48385be5",
   "metadata": {},
   "source": [
    "# üîß Hyperparameter Tuning - Ensemble Models\n",
    "\n",
    "Este notebook optimiza los hiperpar√°metros de los modelos ensemble (Random Forest, Gradient Boosting, AdaBoost) para maximizar su performance.\n",
    "\n",
    "**Estrategia:** Solo optimizamos ensemble models porque ya demostraron ser superiores a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a380068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from configure import DATA_DIR, MODELS_DIR\n",
    "from src.load_data import load_data\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed7898",
   "metadata": {},
   "source": [
    "## üì• Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135042ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: (2113, 22)\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset limpio\n",
    "processed_path = DATA_DIR / 'processed' / 'fetal_health_clean.csv'\n",
    "df = pd.read_csv(processed_path)\n",
    "print(f\"Dataset cargado: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4572dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features y target\n",
    "X = df.drop('fetal_health', axis=1)\n",
    "y = df['fetal_health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075df7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1690, 21) | Test: (423, 21)\n"
     ]
    }
   ],
   "source": [
    "# Train/Test split (mismo que baseline y ensemble para comparaci√≥n justa)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=25, stratify=y\n",
    ")\n",
    "print(f\"Train: {X_train.shape} | Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e90af6d",
   "metadata": {},
   "source": [
    "## üìä Cargar Resultados Base (para comparaci√≥n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22c159f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ ENSEMBLE MODELS (Base - Sin Optimizar)\n",
      "================================================================================\n",
      "            Model  Train Score  Test Score  F1 Score  Recall Score\n",
      "0   Random Forest       0.9994      0.9220    0.9198        0.9220\n",
      "1  Gradient Boost       0.9941      0.9196    0.9183        0.9196\n",
      "2        AdaBoost       0.9095      0.8676    0.8648        0.8676\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar resultados de ensemble models SIN optimizar\n",
    "ensemble_base_df = pd.read_csv(DATA_DIR / 'processed' / 'ensemble_results.csv')\n",
    "print(\"üîπ ENSEMBLE MODELS (Base - Sin Optimizar)\")\n",
    "print(\"=\" * 80)\n",
    "print(ensemble_base_df.sort_values(by='Test Score', ascending=False))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2966e7",
   "metadata": {},
   "source": [
    "## üéØ 1. Random Forest - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "623eed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Buscando mejores hiperpar√°metros para Random Forest...\n",
      "   Total combinaciones: 216\n",
      "   Esto puede tomar varios minutos...\n",
      "\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "‚úÖ Random Forest tuning completado en 187 segundos\n",
      "üèÜ Mejores par√°metros: {'classifier__max_depth': 20, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}\n",
      "üìä Mejor CV Score: 0.9438\n",
      "\n",
      "‚úÖ Random Forest tuning completado en 187 segundos\n",
      "üèÜ Mejores par√°metros: {'classifier__max_depth': 20, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}\n",
      "üìä Mejor CV Score: 0.9438\n"
     ]
    }
   ],
   "source": [
    "# Definir param grid para Random Forest\n",
    "rf_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [10, 20, 30, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "# Pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=25))\n",
    "])\n",
    "\n",
    "# GridSearchCV con Cross-Validation\n",
    "print(\"üîç Buscando mejores hiperpar√°metros para Random Forest...\")\n",
    "print(f\"   Total combinaciones: {np.prod([len(v) for v in rf_param_grid.values()])}\")\n",
    "print(f\"   Esto puede tomar varios minutos...\\n\")\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=rf_pipeline,\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "start_time = datetime.now()\n",
    "rf_grid.fit(X_train, y_train)\n",
    "end_time = datetime.now()\n",
    "\n",
    "print(f\"\\n‚úÖ Random Forest tuning completado en {(end_time - start_time).seconds} segundos\")\n",
    "print(f\"üèÜ Mejores par√°metros: {rf_grid.best_params_}\")\n",
    "print(f\"üìä Mejor CV Score: {rf_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e1fb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ RANDOM FOREST OPTIMIZADO\n",
      "============================================================\n",
      "Train Score: 0.9893\n",
      "Test Score:  0.9362\n",
      "F1 Score:    0.9353\n",
      "Recall:      0.9362\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar Random Forest optimizado\n",
    "rf_best = rf_grid.best_estimator_\n",
    "rf_train_score = rf_best.score(X_train, y_train)\n",
    "rf_test_score = rf_best.score(X_test, y_test)\n",
    "rf_y_pred = rf_best.predict(X_test)\n",
    "rf_f1 = f1_score(y_test, rf_y_pred, average='weighted')\n",
    "rf_recall = recall_score(y_test, rf_y_pred, average='weighted')\n",
    "\n",
    "print(\"üîπ RANDOM FOREST OPTIMIZADO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train Score: {rf_train_score:.4f}\")\n",
    "print(f\"Test Score:  {rf_test_score:.4f}\")\n",
    "print(f\"F1 Score:    {rf_f1:.4f}\")\n",
    "print(f\"Recall:      {rf_recall:.4f}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0178b64b",
   "metadata": {},
   "source": [
    "## üéØ 2. Gradient Boosting - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5287d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Buscando mejores hiperpar√°metros para Gradient Boosting...\n",
      "   Total combinaciones: 972\n",
      "   Esto puede tomar varios minutos...\n",
      "\n",
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n"
     ]
    }
   ],
   "source": [
    "# Definir param grid para Gradient Boosting\n",
    "gb_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__subsample': [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "# Pipeline\n",
    "gb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=25))\n",
    "])\n",
    "\n",
    "# GridSearchCV con Cross-Validation\n",
    "print(\"üîç Buscando mejores hiperpar√°metros para Gradient Boosting...\")\n",
    "print(f\"   Total combinaciones: {np.prod([len(v) for v in gb_param_grid.values()])}\")\n",
    "print(f\"   Esto puede tomar varios minutos...\\n\")\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    estimator=gb_pipeline,\n",
    "    param_grid=gb_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "start_time = datetime.now()\n",
    "gb_grid.fit(X_train, y_train)\n",
    "end_time = datetime.now()\n",
    "\n",
    "print(f\"\\n‚úÖ Gradient Boosting tuning completado en {(end_time - start_time).seconds} segundos\")\n",
    "print(f\"üèÜ Mejores par√°metros: {gb_grid.best_params_}\")\n",
    "print(f\"üìä Mejor CV Score: {gb_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar Gradient Boosting optimizado\n",
    "gb_best = gb_grid.best_estimator_\n",
    "gb_train_score = gb_best.score(X_train, y_train)\n",
    "gb_test_score = gb_best.score(X_test, y_test)\n",
    "gb_y_pred = gb_best.predict(X_test)\n",
    "gb_f1 = f1_score(y_test, gb_y_pred, average='weighted')\n",
    "gb_recall = recall_score(y_test, gb_y_pred, average='weighted')\n",
    "\n",
    "print(\"üîπ GRADIENT BOOSTING OPTIMIZADO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train Score: {gb_train_score:.4f}\")\n",
    "print(f\"Test Score:  {gb_test_score:.4f}\")\n",
    "print(f\"F1 Score:    {gb_f1:.4f}\")\n",
    "print(f\"Recall:      {gb_recall:.4f}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6a56bb",
   "metadata": {},
   "source": [
    "## üéØ 3. AdaBoost - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4508f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir param grid para AdaBoost\n",
    "ada_param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200, 300],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
    "    'classifier__algorithm': ['SAMME', 'SAMME.R'],\n",
    "}\n",
    "\n",
    "# Pipeline\n",
    "ada_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', AdaBoostClassifier(random_state=25))\n",
    "])\n",
    "\n",
    "# GridSearchCV con Cross-Validation\n",
    "print(\"üîç Buscando mejores hiperpar√°metros para AdaBoost...\")\n",
    "print(f\"   Total combinaciones: {np.prod([len(v) for v in ada_param_grid.values()])}\")\n",
    "print(f\"   Esto puede tomar varios minutos...\\n\")\n",
    "\n",
    "ada_grid = GridSearchCV(\n",
    "    estimator=ada_pipeline,\n",
    "    param_grid=ada_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "start_time = datetime.now()\n",
    "ada_grid.fit(X_train, y_train)\n",
    "end_time = datetime.now()\n",
    "\n",
    "print(f\"\\n‚úÖ AdaBoost tuning completado en {(end_time - start_time).seconds} segundos\")\n",
    "print(f\"üèÜ Mejores par√°metros: {ada_grid.best_params_}\")\n",
    "print(f\"üìä Mejor CV Score: {ada_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb008ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar AdaBoost optimizado\n",
    "ada_best = ada_grid.best_estimator_\n",
    "ada_train_score = ada_best.score(X_train, y_train)\n",
    "ada_test_score = ada_best.score(X_test, y_test)\n",
    "ada_y_pred = ada_best.predict(X_test)\n",
    "ada_f1 = f1_score(y_test, ada_y_pred, average='weighted')\n",
    "ada_recall = recall_score(y_test, ada_y_pred, average='weighted')\n",
    "\n",
    "print(\"üîπ ADABOOST OPTIMIZADO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train Score: {ada_train_score:.4f}\")\n",
    "print(f\"Test Score:  {ada_test_score:.4f}\")\n",
    "print(f\"F1 Score:    {ada_f1:.4f}\")\n",
    "print(f\"Recall:      {ada_recall:.4f}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2c030",
   "metadata": {},
   "source": [
    "## üìä Comparaci√≥n: Base vs Optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con resultados optimizados\n",
    "optimized_results = [\n",
    "    ['Random Forest', rf_train_score, rf_test_score, rf_f1, rf_recall],\n",
    "    ['Gradient Boosting', gb_train_score, gb_test_score, gb_f1, gb_recall],\n",
    "    ['AdaBoost', ada_train_score, ada_test_score, ada_f1, ada_recall]\n",
    "]\n",
    "\n",
    "optimized_df = pd.DataFrame(\n",
    "    optimized_results,\n",
    "    columns=['Model', 'Train Score', 'Test Score', 'F1 Score', 'Recall Score']\n",
    ")\n",
    "optimized_df = optimized_df.round(4)\n",
    "\n",
    "print(\"üöÄ ENSEMBLE MODELS OPTIMIZADOS\")\n",
    "print(\"=\" * 80)\n",
    "print(optimized_df.sort_values(by='Test Score', ascending=False))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc50f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n lado a lado\n",
    "comparison_data = []\n",
    "\n",
    "for model_name in ['Random Forest', 'Gradient Boosting', 'AdaBoost']:\n",
    "    base_score = ensemble_base_df[ensemble_base_df['Model'] == model_name]['Test Score'].values[0]\n",
    "    opt_score = optimized_df[optimized_df['Model'] == model_name]['Test Score'].values[0]\n",
    "    improvement_abs = opt_score - base_score\n",
    "    improvement_rel = (improvement_abs / base_score) * 100\n",
    "    \n",
    "    comparison_data.append([\n",
    "        model_name,\n",
    "        base_score,\n",
    "        opt_score,\n",
    "        improvement_abs,\n",
    "        improvement_rel\n",
    "    ])\n",
    "\n",
    "comparison_df = pd.DataFrame(\n",
    "    comparison_data,\n",
    "    columns=['Model', 'Base Score', 'Optimized Score', 'Improvement (Abs)', 'Improvement (%)']\n",
    ")\n",
    "comparison_df = comparison_df.round(4)\n",
    "\n",
    "print(\"üìà COMPARACI√ìN: BASE vs OPTIMIZADO\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.sort_values(by='Improvement (%)', ascending=False))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d1bca2",
   "metadata": {},
   "source": [
    "## üìä Visualizaci√≥n Comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e071f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico de comparaci√≥n Base vs Optimizado\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Scores Base vs Optimizado\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "ax1 = axes[0]\n",
    "bars1 = ax1.bar(x - width/2, comparison_df['Base Score'], width, label='Base', alpha=0.8, color='#3498db')\n",
    "bars2 = ax1.bar(x + width/2, comparison_df['Optimized Score'], width, label='Optimized', alpha=0.8, color='#e74c3c')\n",
    "\n",
    "ax1.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Test Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Base vs Optimized - Test Scores', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(comparison_df['Model'], rotation=15, ha='right')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax1.set_ylim([0.85, 1.0])\n",
    "\n",
    "# A√±adir valores en las barras\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 2: Mejora porcentual\n",
    "ax2 = axes[1]\n",
    "bars3 = ax2.bar(comparison_df['Model'], comparison_df['Improvement (%)'], \n",
    "                alpha=0.8, color='#2ecc71', edgecolor='black')\n",
    "\n",
    "ax2.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Improvement (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Mejora Relativa despu√©s del Tuning', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticklabels(comparison_df['Model'], rotation=15, ha='right')\n",
    "ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "\n",
    "# A√±adir valores en las barras\n",
    "for bar in bars3:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "            f'{height:.2f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ccac20",
   "metadata": {},
   "source": [
    "## üèÜ Identificar Mejor Modelo Optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52257807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar el mejor modelo optimizado\n",
    "best_idx = optimized_df['Test Score'].idxmax()\n",
    "best_model_name = optimized_df.loc[best_idx, 'Model']\n",
    "best_test_score = optimized_df.loc[best_idx, 'Test Score']\n",
    "best_f1 = optimized_df.loc[best_idx, 'F1 Score']\n",
    "best_recall = optimized_df.loc[best_idx, 'Recall Score']\n",
    "\n",
    "# Obtener el modelo correspondiente\n",
    "if best_model_name == 'Random Forest':\n",
    "    best_model = rf_best\n",
    "    best_params = rf_grid.best_params_\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    best_model = gb_best\n",
    "    best_params = gb_grid.best_params_\n",
    "else:  # AdaBoost\n",
    "    best_model = ada_best\n",
    "    best_params = ada_grid.best_params_\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üèÜ MEJOR MODELO OPTIMIZADO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Modelo:       {best_model_name}\")\n",
    "print(f\"Test Score:   {best_test_score:.4f}\")\n",
    "print(f\"F1 Score:     {best_f1:.4f}\")\n",
    "print(f\"Recall Score: {best_recall:.4f}\")\n",
    "print(\"\\nMejores Par√°metros:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  - {param}: {value}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d123b9",
   "metadata": {},
   "source": [
    "## üéØ Matriz de Confusi√≥n del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe6de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusi√≥n del mejor modelo optimizado\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Normal', 'Suspect', 'Pathological'], \n",
    "            yticklabels=['Normal', 'Suspect', 'Pathological'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.ylabel('Actual', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Predicted', fontsize=13, fontweight='bold')\n",
    "plt.title(f'Confusion Matrix - {best_model_name} (Optimized)', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c592f7",
   "metadata": {},
   "source": [
    "## üìã Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d51b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report detallado\n",
    "print(\"üìä CLASSIFICATION REPORT - MEJOR MODELO\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(y_test, y_pred_best, \n",
    "                          target_names=['Normal', 'Suspect', 'Pathological']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da01c0fb",
   "metadata": {},
   "source": [
    "## üíæ Guardar Resultados y Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados optimizados\n",
    "optimized_df.to_csv(DATA_DIR / 'processed' / 'optimized_results.csv', index=False)\n",
    "print(f\"‚úÖ Resultados optimizados guardados en: {DATA_DIR / 'processed' / 'optimized_results.csv'}\")\n",
    "\n",
    "# Guardar comparaci√≥n\n",
    "comparison_df.to_csv(DATA_DIR / 'processed' / 'tuning_comparison.csv', index=False)\n",
    "print(f\"‚úÖ Comparaci√≥n guardada en: {DATA_DIR / 'processed' / 'tuning_comparison.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar mejor modelo optimizado\n",
    "model_filename = MODELS_DIR / f'best_model_{best_model_name.replace(\" \", \"_\").lower()}_optimized.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(f\"‚úÖ Mejor modelo guardado en: {model_filename}\")\n",
    "\n",
    "# Guardar metadata del mejor modelo\n",
    "best_model_metadata = {\n",
    "    'model_name': best_model_name,\n",
    "    'test_score': best_test_score,\n",
    "    'f1_score': best_f1,\n",
    "    'recall_score': best_recall,\n",
    "    'best_params': best_params,\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "metadata_filename = MODELS_DIR / 'best_model_metadata.pkl'\n",
    "with open(metadata_filename, 'wb') as f:\n",
    "    pickle.dump(best_model_metadata, f)\n",
    "\n",
    "print(f\"‚úÖ Metadata guardada en: {metadata_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a7d33",
   "metadata": {},
   "source": [
    "## üìã Resumen Final del Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968baca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üìä RESUMEN FINAL - HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüéØ Modelos Optimizados:\")\n",
    "for _, row in comparison_df.iterrows():\n",
    "    print(f\"\\n  {row['Model']}:\")\n",
    "    print(f\"    Base Score:      {row['Base Score']:.4f}\")\n",
    "    print(f\"    Optimized Score: {row['Optimized Score']:.4f}\")\n",
    "    print(f\"    Mejora:          {row['Improvement (Abs)']:.4f} ({row['Improvement (%)']:.2f}%)\")\n",
    "\n",
    "print(f\"\\n\\nüèÜ MODELO FINAL SELECCIONADO:\")\n",
    "print(f\"   {best_model_name}\")\n",
    "print(f\"   Test Score: {best_test_score:.4f}\")\n",
    "print(f\"   F1 Score:   {best_f1:.4f}\")\n",
    "print(f\"\\nüìÅ Archivos generados:\")\n",
    "print(f\"   - {DATA_DIR / 'processed' / 'optimized_results.csv'}\")\n",
    "print(f\"   - {DATA_DIR / 'processed' / 'tuning_comparison.csv'}\")\n",
    "print(f\"   - {model_filename}\")\n",
    "print(f\"   - {metadata_filename}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19cf7f8",
   "metadata": {},
   "source": [
    "## üéØ Conclusiones\n",
    "\n",
    "### Resultados del Tuning:\n",
    "- **Modelos optimizados:** Random Forest, Gradient Boosting, AdaBoost\n",
    "- **Mejor modelo:** [Se completa autom√°ticamente al ejecutar]\n",
    "- **Mejora obtenida:** [Se completa autom√°ticamente al ejecutar]\n",
    "\n",
    "### Observaciones:\n",
    "- GridSearchCV con 5-fold CV garantiza robustez\n",
    "- Los par√°metros √≥ptimos var√≠an seg√∫n el modelo\n",
    "- Gradient Boosting suele mostrar mayor mejora con tuning\n",
    "- Random Forest es m√°s robusto con par√°metros por defecto\n",
    "\n",
    "### Pr√≥ximos Pasos:\n",
    "- ‚úÖ Modelos ensemble optimizados\n",
    "- ‚úÖ Mejor modelo identificado y guardado\n",
    "- ‚è≠Ô∏è Evaluaci√≥n profunda con learning curves\n",
    "- ‚è≠Ô∏è Feature importance analysis\n",
    "- ‚è≠Ô∏è Pipeline de deployment/inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
